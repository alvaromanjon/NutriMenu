\capitulo{4}{Técnicas y herramientas}

\section{Patrón de diseño Modelo-Vista-Controlador (MVC)}

\imagen{MVC/diagrama-mvc}{Diagrama del patrón Modelo-Vista-Controlador}{0.9}

La función del patrón de diseño conocido como \textbf{Modelo-Vista-Controlador} es la de organizar de forma estructurada los componentes fundamentales de un determinado \textit{sistema de software}, estableciendo relaciones entre ellos.

Como metodología de trabajo, fue propuesta por Trygve Reenskaug en 1979, basándose su utilidad en tres ideas fundamentales \cite{campusmvp:mvc}:

\begin{itemize}
\item La organización y clasificación de la información que se aporta al sistema.
\item La unificación y gestión de la lógica del sistema.
\item La presentación de datos al usuario mediante una interfaz comprensible y asequible.
\end{itemize}

Los tres componentes fundamentales de este patrón tienen misiones diferenciadas sobre la forma en cómo tratan la información \cite{easyappcode:mvc}: 

\begin{itemize}
\item \textbf{Modelo}: Es el componente cuya misión es únicamente la de gestionar el contenido de una base de datos, incluida su manipulación y utilización. Es la parte que se va a encargar de la \textbf{gestión de los datos}.
\item \textbf{Vista}: Es el componente que sirve para acceder al contenido de la base de datos y presentar los datos al usuario. Va a ser \textbf{la parte con la que va a interactuar el usuario}.
\item \textbf{Controlador}: Este componente es el que pone en conexión el modelo y la vista, gestionando y procesando las instrucciones que se reciben para obtener un resultado. Su forma básica de trabajar consiste en acceder a la base de datos, manipularlos con una determinada finalidad y presentar los resultados de esa manipulación de los datos. Se va a encargar de gestionar \textbf{la lógica y la gestión de los datos}.
\end{itemize}
El motivo por el cual he decidido utilizar este patrón es porque permite trabajar de una forma precisa y eficaz, haciendo que la estructura del sistema sea clara, ordenada y separada, lo que facilita su comprensión y posterior mantenimiento.  

\section{Contenerización}

\begin{comment}
	Esta parte de la memoria tiene como objetivo presentar las técnicas metodológicas y las herramientas de desarrollo que se han utilizado para llevar a cabo el proyecto. Si se han estudiado diferentes alternativas de metodologías, herramientas, bibliotecas se puede hacer un resumen de los aspectos más destacados de cada alternativa, incluyendo comparativas entre las distintas opciones y una justificación de las elecciones realizadas. 
No se pretende que este apartado se convierta en un capítulo de un libro dedicado a cada una de las alternativas, sino comentar los aspectos más destacados de cada opción, con un repaso somero a los fundamentos esenciales y referencias bibliográficas para que el lector pueda ampliar su conocimiento sobre el tema.
\end{comment}

\begin{comment}
	TODO: Hacer introducción de esta sección
\end{comment}

Se conoce como contenerización a la tecnología de virtualización que permite ejecutar \textbf{contenedores}, entornos completamente aislados del resto de la máquina que los está ejecutando, y que contienen todo lo necesario (bibliotecas, código, archivos de configuración, dependencias...) para que se pueda ejecutar una aplicación en cualquier entorno.\cite{microsoft:contenedores}

A diferencia de entornos clásicos de virtualización como las \textbf{máquinas virtuales}, en los que se emula el hardware por completo y se debe disponer de una instalación completa del sistema operativo para funcionar, en los contenedores se permite que múltiples instancias compartan un mismo sistema operativo, a pesar de estar usando espacios de ejecución distintos. Esto se consigue usando características de Linux como los \textit{espacios de nombres del kernel} o los \textit{cgroups} \cite{medium:kernelspace}, puesto que los contenedores están basados en Linux, pero esto no impide su ejecución en distintas plataformas y sistemas operativos, incluido Windows.
 
\subsection{Docker}

Docker es una plataforma de código abierto que permite el desarrollo, ejecución y distribución de aplicaciones en contenedores.

\subsubsection{Arquitectura de Docker}

\imagen{Docker/docker_architecture}{Arquitectura de Docker}{0.75}

La arquitectura de Docker es una arquitectura \textbf{cliente-servidor} \cite{docker:overview-architecture}. El cliente de Docker, que es con lo que interactúa el usuario, habla con el \textit{daemon} haciendo llamadas API REST, y este se encarga de gestionar las peticiones y los objetos de Docker, como son las imágenes, los contenedores, los volúmenes y las redes. Finalmente, para conseguir las imágenes, el \textit{daemon} habla con \textit{Docker Registry}, el repositorio que contiene todas las imágenes necesarias para el despliegue. Por defecto se usa \textbf{Docker Hub}, un repositorio público en el que cualquiera puede subir y descargar imágenes, pero se puede usar también un repositorio privado.

\subsubsection{Imágenes}

Las imágenes son plantillas que contienen instrucciones y parámetros para crear contenedores de Docker. Se puede crear un contenedor usando directamente una imagen del \textit{registry}, reutilizando imágenes ya existentes como base para crear nuestras propias imágenes, o incluso creando nuestras propias imágenes desde cero. Las imágenes se crean usando archivos \textit{Dockerfile}, añadiendo en él las distintas dependencias, instrucciones y parámetros, y cada uno de estos elementos es una capa dentro de la imagen. De esta manera, cada vez que se modifica el \textit{Dockerfile} y se vuelve a construir la imagen, realmente sólo se vuelven a construir las capas en las que han habido cambios, acelerando de esta forma el proceso de despliegue.
\cite{docker:overview-objects}

\subsection{Docker Compose}

Docker Compose es una herramienta que nos permite definir, orquestrar, desplegar y escalar \textbf{aplicaciones Docker multi-contenedor}. \cite{docker-compose:overview} Para ello, se define un archivo \textit{YAML} en el que se van a definir las  configuraciones necesarias para los distintos servicios pertenecientes a la aplicación. Esto nos va a permitir establecer relaciones y dependencias entre distintos contenedores que forman parte de un mismo aplicativo, permitiendo así que varios contenedores formen parte de una misma red o tengan la capacidad de compartir volúmenes de almacenamiento, por poner unos ejemplos.

He decidido usar esta herramienta ya que facilita bastante la conexión e integración entre los distintos servicios que componen la aplicación, como son la base de datos, el backend, y el frontend. Además de esto, a la hora de poner la aplicación en producción, obtenemos varias ventajas respecto a un entorno tradicional:

\begin{itemize}

\item \textbf{Automatización de despliegues}, ya que una vez hayamos definido en el archivo de configuración de Docker Compose todas las dependencias, configuraciones y relaciones necesarias, con un sólo comando Docker Compose se va a encargar de crear y desplegar los contenedores, configurar los elementos necesarios, e iniciar los servicios.
\item \textbf{Creación de entornos aislados y consistentes}, lo que nos permite desplegar entornos de desarrollo locales, así como entornos CI/CD de validación y pruebas, y que estos repliquen la infraestructura de producción, que también puede ser desplegada usando Docker Compose.
\item \textbf{Escalabilidad de infraestructura}, puesto que con un sólo comando podemos aumentar o disminuir el número de instancias de las que dispone un servicio.	
\end{itemize}

